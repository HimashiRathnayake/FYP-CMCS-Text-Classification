{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train Task Adapters.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HimashiRathnayake/CMCS-Text-Classification/blob/main/XLM-R/Train_Task_Adapters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoL8-pXx9z7c"
      },
      "source": [
        "## Training Single Task Adapters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCdvw5JNlygg"
      },
      "source": [
        "### **Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LjxhVXklun6"
      },
      "source": [
        "technique = \"hate speech\" #@param [\"humor\", \"hate speech\"]\n",
        "over_sampling_technique = \"\" #@param [\"\", \"ROS\",\"ADASYN\", \"SMOTE\", \"BorderlineSMOTE\"]\n",
        "sampling_strategy = \"\" #@param [] {allow-input: true} \n",
        "# eg: 1:0.25:0.25 for hate speech"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L9gYpCV28OA"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL3Sq1HQynCq"
      },
      "source": [
        "# !pip install -U adapter-transformers\n",
        "# !pip install datasets\n",
        "# !pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUHpDE_Gtyen"
      },
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJZ6z8bJl25l"
      },
      "source": [
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaConfig, XLMRobertaModelWithHeads, TrainingArguments, AdapterTrainer, EvalPrediction, TextClassificationPipeline\n",
        "import torch\n",
        "from datasets import load_metric\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDIvwCzMP_WF",
        "outputId": "ce418833-2827-472b-fc23-e47b2d8606d8"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzrDM6Ua-jo_"
      },
      "source": [
        "### Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB8pw1RDuDaA"
      },
      "source": [
        "def apply_oversampling(x, y):\n",
        "\n",
        "  (unique, counts) = np.unique(y, axis=0, return_counts=True)\n",
        "  print(\"Class Distribution Without Oversampling\", counts)\n",
        "\n",
        "  # define oversampling strategy\n",
        "  if (over_sampling_technique == \"\"):\n",
        "    return x, y\n",
        "  elif (over_sampling_technique == \"ROS\"):\n",
        "    if (technique==\"humor\"):\n",
        "      oversample = RandomOverSampler(sampling_strategy = float(sampling_strategy))\n",
        "    else:\n",
        "      sampling_ratio = sampling_strategy.split(\":\");\n",
        "      oversample = RandomOverSampler(sampling_strategy = {\n",
        "          0:int(counts[0]*float(sampling_ratio[0])), \n",
        "          1:int(counts[0]*float(sampling_ratio[1])), \n",
        "          2:int(counts[0]*float(sampling_ratio[2]))\n",
        "          })\n",
        "  elif (over_sampling_technique == \"ADASYN\"):\n",
        "    oversample = ADASYN(sampling_strategy=\"minority\")\n",
        "  elif (over_sampling_technique == \"SMOTE\"):\n",
        "    oversample = SMOTE()\n",
        "  elif (over_sampling_technique == \"BorderlineSMOTE\"):\n",
        "    oversample = BorderlineSMOTE()\n",
        "\n",
        "  # fit and apply the transform\n",
        "  X_over, y_over = oversample.fit_resample(x, y)\n",
        "\n",
        "  (unique, counts) = np.unique(y_over, axis=0, return_counts=True)\n",
        "  print(\"Class Distribution After Oversampling\", counts)\n",
        "\n",
        "  return X_over, y_over"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MUpioPlmvMh"
      },
      "source": [
        "dataset_path = \"/content/drive/Shareddrives/FYP/corpus/Ã§ompleted_draft.csv\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq5AMmjelqlj"
      },
      "source": [
        "all_data = pd.read_csv(dataset_path)\n",
        "\n",
        "if (technique == \"humor\"):\n",
        "  all_data = all_data[['Sentence', 'Humor']]\n",
        "elif (technique == \"hate speech\"):\n",
        "  all_data = all_data[['Sentence', 'Hate_speech']]\n",
        "else:\n",
        "  all_data = all_data[['Sentence', 'Offensive']]\n",
        "\n",
        "all_data.columns = ['Sentence', 'Label']\n",
        "all_data['Label'], uniq = pd.factorize(all_data['Label'])\n",
        "\n",
        "X = all_data['Sentence'].values.tolist()\n",
        "y = all_data['Label'].values.tolist()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQp6K1g3mVrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "391121da-9535-4ee7-cbf8-946477371992"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 42)\n",
        "\n",
        "# uncomment following only when applying oversampling\n",
        "X_train = np.array(X_train).reshape(-1, 1)\n",
        "X_train, y_train = apply_oversampling(X_train, y_train)\n",
        "X_train = [x[0] for x in X_train.tolist()]\n",
        "# y_train = y_train.tolist()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution Without Oversampling [11036   314   816]\n",
            "Class Distribution After Oversampling [11036  2759  2759]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCUWfe8-n0i8"
      },
      "source": [
        "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\", do_lower_case=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqXJtJe8oObQ"
      },
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "def encode_batch(batch):\n",
        "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
        "  return tokenizer(batch, max_length=MAX_LEN, truncation=True, padding=\"max_length\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcwOeBZyov3K"
      },
      "source": [
        "# Encode the input data\n",
        "encoded_X_train = encode_batch(X_train)\n",
        "encoded_X_test = encode_batch(X_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6581Al-K_Nyf"
      },
      "source": [
        "class DatasetObject(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = DatasetObject(encoded_X_train, y_train)\n",
        "test_dataset = DatasetObject(encoded_X_test, y_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCwk6iQE_XZb"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEiosRF68JMq"
      },
      "source": [
        "if (technique == 'humor'):\n",
        "    num_labels=2\n",
        "    id2label={ 0: \"Non-humorous\", 1: \"Humorous\"}\n",
        "elif (technique == 'hate speech'):\n",
        "    num_labels=3\n",
        "    id2label={ 0: \"Not offensive\", 1: \"Hate-Inducing\", 2: \"Abusive\"}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNyi1nFH_TOS",
        "outputId": "8c20fe58-21c4-4f26-f38a-906e8d363fb1"
      },
      "source": [
        "config = XLMRobertaConfig.from_pretrained(\n",
        "    \"xlm-roberta-base\",\n",
        "    num_labels= num_labels,\n",
        ")\n",
        "\n",
        "model = XLMRobertaModelWithHeads.from_pretrained(\n",
        "    \"xlm-roberta-base\",\n",
        "    config=config,\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaModelWithHeads were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RPhSipb_diC"
      },
      "source": [
        "# Add a new adapter\n",
        "model.add_adapter(\"task_\"+technique)\n",
        "\n",
        "# Add a matching classification head\n",
        "model.add_classification_head(\n",
        "    \"task_\"+technique,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label\n",
        "  )\n",
        "\n",
        "# Activate the adapter\n",
        "model.train_adapter(\"task_\"+technique)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNAHk2IE_fgS"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    learning_rate=1e-4,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    # logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    # overwrite_output_dir=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "def compute_accuracy(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  return {\"acc\": (preds == p.label_ids).mean()}\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    metric1 = load_metric(\"precision\")\n",
        "    metric2 = load_metric(\"recall\")\n",
        "    metric3 = load_metric(\"f1\")\n",
        "    metric4 = load_metric(\"accuracy\")\n",
        "    \n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    precision = metric1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"precision\"]\n",
        "    recall = metric2.compute(predictions=predictions, references=labels, average=\"weighted\")[\"recall\"]\n",
        "    f1 = metric3.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
        "    accuracy = metric4.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    macro_precision = metric1.compute(predictions=predictions, references=labels, average=\"macro\")[\"precision\"]\n",
        "    macro_recall = metric2.compute(predictions=predictions, references=labels, average=\"macro\")[\"recall\"]\n",
        "    macro_f1 = metric3.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
        "    return {\"accuracy\":accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"macro_precision\": macro_precision, \"macro_recall\": macro_recall, \"macro_f1\": macro_f1}\n",
        "\n",
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "xuqQODvG_kB-",
        "outputId": "98774e32-7bf1-450a-b280-1b6e92839e80"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 16554\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1554\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1554' max='1554' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1554/1554 24:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.739200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.565600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.499800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./training_output/checkpoint-500\n",
            "Configuration saved in ./training_output/checkpoint-500/task_hate speech/adapter_config.json\n",
            "Module weights saved in ./training_output/checkpoint-500/task_hate speech/pytorch_adapter.bin\n",
            "Configuration saved in ./training_output/checkpoint-500/task_hate speech/head_config.json\n",
            "Module weights saved in ./training_output/checkpoint-500/task_hate speech/pytorch_model_head.bin\n",
            "Configuration saved in ./training_output/checkpoint-500/task_hate speech/head_config.json\n",
            "Module weights saved in ./training_output/checkpoint-500/task_hate speech/pytorch_model_head.bin\n",
            "Configuration saved in ./training_output/checkpoint-500/task_hate speech/head_config.json\n",
            "Module weights saved in ./training_output/checkpoint-500/task_hate speech/pytorch_model_head.bin\n",
            "Saving model checkpoint to ./training_output/checkpoint-1000\n",
            "Configuration saved in ./training_output/checkpoint-1000/task_hate speech/adapter_config.json\n",
            "Module weights saved in ./training_output/checkpoint-1000/task_hate speech/pytorch_adapter.bin\n",
            "Configuration saved in ./training_output/checkpoint-1000/task_hate speech/head_config.json\n",
            "Module weights saved in ./training_output/checkpoint-1000/task_hate speech/pytorch_model_head.bin\n",
            "Configuration saved in ./training_output/checkpoint-1000/task_hate speech/head_config.json\n",
            "Module weights saved in ./training_output/checkpoint-1000/task_hate speech/pytorch_model_head.bin\n",
            "Configuration saved in ./training_output/checkpoint-1000/task_hate speech/head_config.json\n",
            "Module weights saved in ./training_output/checkpoint-1000/task_hate speech/pytorch_model_head.bin\n",
            "Saving model checkpoint to ./training_output/checkpoint-1500\n",
            "Configuration saved in ./training_output/checkpoint-1500/task_hate speech/adapter_config.json\n",
            "Module weights saved in ./training_output/checkpoint-1500/task_hate speech/pytorch_adapter.bin\n",
            "Configuration saved in ./training_output/checkpoint-1500/task_hate speech/head_config.json\n",
            "Module weights saved in ./training_output/checkpoint-1500/task_hate speech/pytorch_model_head.bin\n",
            "Configuration saved in ./training_output/checkpoint-1500/task_hate speech/head_config.json\n",
            "Module weights saved in ./training_output/checkpoint-1500/task_hate speech/pytorch_model_head.bin\n",
            "Configuration saved in ./training_output/checkpoint-1500/task_hate speech/head_config.json\n",
            "Module weights saved in ./training_output/checkpoint-1500/task_hate speech/pytorch_model_head.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1554, training_loss=0.5981188127279589, metrics={'train_runtime': 1491.0865, 'train_samples_per_second': 33.306, 'train_steps_per_second': 1.042, 'total_flos': 3323327732411904.0, 'train_loss': 0.5981188127279589, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "Frvx7oS5APqa",
        "outputId": "0faf1dfc-266a-438f-f451-c9d811299e6c"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [43/43 00:18]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.8838757396449705,\n",
              " 'eval_f1': 0.8965210679806407,\n",
              " 'eval_loss': 0.31348752975463867,\n",
              " 'eval_macro_f1': 0.6150233465267023,\n",
              " 'eval_macro_precision': 0.5707390518497717,\n",
              " 'eval_macro_recall': 0.7364296452675686,\n",
              " 'eval_precision': 0.9164654593871178,\n",
              " 'eval_recall': 0.8838757396449705,\n",
              " 'eval_runtime': 20.6061,\n",
              " 'eval_samples_per_second': 65.612,\n",
              " 'eval_steps_per_second': 2.087}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3U0IIfyBM7b",
        "outputId": "a6dabee0-e77b-484e-f39e-e9b499752fe6"
      },
      "source": [
        "classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer, device=training_args.device.index)\n",
        "\n",
        "classifier(\"Lolð\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'Not offensive', 'score': 0.7908138036727905}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jjacTz4P1Id",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e0d3e63-adb1-4800-985d-7198c258e65a"
      },
      "source": [
        "model.save_adapter(\"/content/drive/Shareddrives/FYP-CodeStars/Implementation/TrainedAdapters/task_adapter_\"+technique, \"task_\"+technique)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/drive/Shareddrives/FYP-CodeStars/Implementation/TrainedAdapters/task_adapter_hate speech/adapter_config.json\n",
            "Module weights saved in /content/drive/Shareddrives/FYP-CodeStars/Implementation/TrainedAdapters/task_adapter_hate speech/pytorch_adapter.bin\n",
            "Configuration saved in /content/drive/Shareddrives/FYP-CodeStars/Implementation/TrainedAdapters/task_adapter_hate speech/head_config.json\n",
            "Module weights saved in /content/drive/Shareddrives/FYP-CodeStars/Implementation/TrainedAdapters/task_adapter_hate speech/pytorch_model_head.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB7IEuOXWA-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69dbb3a4-8600-4cdc-db15-2f7a5bcaaafd"
      },
      "source": [
        "classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer, device=training_args.device.index)\n",
        "\n",
        "classifier(\"This is great!\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'Not offensive', 'score': 0.9991517066955566}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbvg2bAotknP"
      },
      "source": [
        "## Load Adapters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tIYHCxYrCzb"
      },
      "source": [
        "# config = XLMRobertaConfig.from_pretrained(\n",
        "#     \"xlm-roberta-base\",\n",
        "#     num_labels=2,\n",
        "# )\n",
        "\n",
        "# model = XLMRobertaModelWithHeads.from_pretrained(\n",
        "#     \"xlm-roberta-base\",\n",
        "#     config=config,\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tLKB4hJtqER"
      },
      "source": [
        "# model.load_adapter(\"/content/drive/Shareddrives/FYP-CodeStars/Implementation/TrainedAdapters/task_adapter_hate speech\", with_head=False)\n",
        "# model.set_active_adapters(\"task_\"+technique)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccpvu1QYtsxA"
      },
      "source": [
        "# tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\", do_lower_case=True)\n",
        "# classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYDH-Y5xrRoZ"
      },
      "source": [
        "# classifier(\"This is awesome!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB5oqzMj5QhB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}