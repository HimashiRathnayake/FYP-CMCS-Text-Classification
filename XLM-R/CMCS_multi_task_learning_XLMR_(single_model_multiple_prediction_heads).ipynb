{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-task learning XLM-R.ipynb (Single Model Multiple Prediction Heads)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cdb2d0f45f874b8bb5119801a7ce5399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9bb37b484c8c4f3b8971890d157fd11f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bbcad7709f824a4896202106ba1a72ee",
              "IPY_MODEL_ddabccdbd498420891d0daf5d4927324",
              "IPY_MODEL_aa732a5a3d634e04a285890bbe07b79e"
            ]
          }
        },
        "9bb37b484c8c4f3b8971890d157fd11f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bbcad7709f824a4896202106ba1a72ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_97ca980f5246466a8c728b134316cdaa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b00b04fc068493a99a8d82ef34ee5e1"
          }
        },
        "ddabccdbd498420891d0daf5d4927324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df592d5b2e454e9289db7ba65688afae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93a1f187552a46d1ad151f0b901a5669"
          }
        },
        "aa732a5a3d634e04a285890bbe07b79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3763b6daef2248dea55cef92d1f28a49",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00, 50.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1732ca7b88134f34b2390c661c0af0d9"
          }
        },
        "97ca980f5246466a8c728b134316cdaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b00b04fc068493a99a8d82ef34ee5e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df592d5b2e454e9289db7ba65688afae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93a1f187552a46d1ad151f0b901a5669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3763b6daef2248dea55cef92d1f28a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1732ca7b88134f34b2390c661c0af0d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6914c03d01d49a8a5f96abf357251ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb702ae270e64c6cb27b2013b9444fcb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c4a99603814547d88cbb6bc7373f78d7",
              "IPY_MODEL_b631233f0af947d093075645b7fd1549",
              "IPY_MODEL_7f86d36d71ac4a679ce387418c5bc359"
            ]
          }
        },
        "fb702ae270e64c6cb27b2013b9444fcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4a99603814547d88cbb6bc7373f78d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a2e1fa9222f4e0ca90a394d1ebe8f62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Running tokenizer on dataset: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a133950e2f574b7ea342afd35269154e"
          }
        },
        "b631233f0af947d093075645b7fd1549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8de4c137a444b8f960bad048e7bb500",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42b4b88bdf4140569509e88ec2efa82a"
          }
        },
        "7f86d36d71ac4a679ce387418c5bc359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_041c0de5c10e42858fe08fcb7bbce5f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00,  7.52ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f75948d7c56243599209379747c932ce"
          }
        },
        "8a2e1fa9222f4e0ca90a394d1ebe8f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a133950e2f574b7ea342afd35269154e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8de4c137a444b8f960bad048e7bb500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42b4b88bdf4140569509e88ec2efa82a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "041c0de5c10e42858fe08fcb7bbce5f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f75948d7c56243599209379747c932ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b981258076634e6bb64b27b5c67c5a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03ce92528ba44d2fa48eb1a655293aaa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ff38f49f2464b15a6877382dda6f796",
              "IPY_MODEL_fde148cc39e4485bb25bc5d970a06ec4",
              "IPY_MODEL_afbe4437399340918039777567baded5"
            ]
          }
        },
        "03ce92528ba44d2fa48eb1a655293aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ff38f49f2464b15a6877382dda6f796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_490f205d353c4a3ab8144c0c54e1dd6c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2573c5ba5364024b86bd4de48bb796b"
          }
        },
        "fde148cc39e4485bb25bc5d970a06ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c2c79764d13040f08ad7200a86c32ae1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86ff1ca464fa455f9e6b47ac2b080e3c"
          }
        },
        "afbe4437399340918039777567baded5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_88c76e4c7d3e404f9ff2ca7c52ac0dbb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00, 41.93it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c1bebf7def7474ebd4e9a568b6b8305"
          }
        },
        "490f205d353c4a3ab8144c0c54e1dd6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2573c5ba5364024b86bd4de48bb796b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2c79764d13040f08ad7200a86c32ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86ff1ca464fa455f9e6b47ac2b080e3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88c76e4c7d3e404f9ff2ca7c52ac0dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c1bebf7def7474ebd4e9a568b6b8305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f757735901a4ceba6d6320aaf64c1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f504de45539f4d7da003ea8e938d1466",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db94c0ecb210485e9e80312cf98158d3",
              "IPY_MODEL_d62cd1b38a6c4084aee8427955c70b50",
              "IPY_MODEL_0774ddf6df7b4cec8f4824c8856cc6d0"
            ]
          }
        },
        "f504de45539f4d7da003ea8e938d1466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db94c0ecb210485e9e80312cf98158d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cbd2555633574c1db3f83eea43b7450d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36f35d95617c45aea109c5df9e8b58cb"
          }
        },
        "d62cd1b38a6c4084aee8427955c70b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_79d85333b387418a86fbc32d72c2b5e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2d15581ccd54720a3c576122ba76028"
          }
        },
        "0774ddf6df7b4cec8f4824c8856cc6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_25250bff22ef4448a2ad00371d573ff3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00, 48.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52dae32a698542c38568006a38a8057e"
          }
        },
        "cbd2555633574c1db3f83eea43b7450d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36f35d95617c45aea109c5df9e8b58cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79d85333b387418a86fbc32d72c2b5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2d15581ccd54720a3c576122ba76028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25250bff22ef4448a2ad00371d573ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52dae32a698542c38568006a38a8057e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8a07829f8104db2bc91ae5759005e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c0069bf396d44bd9b2c390fb38ae2240",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f13d97a3a144eaa9a54b834954e0028",
              "IPY_MODEL_b0e28d61b748468a982e770d18b4552a",
              "IPY_MODEL_f57ffa8dbb6b42c8a7c1f51084d10c29"
            ]
          }
        },
        "c0069bf396d44bd9b2c390fb38ae2240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f13d97a3a144eaa9a54b834954e0028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cecb88b7544a425888ac714327e8ea43",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dec226a6334c47d2ba948938f9f28381"
          }
        },
        "b0e28d61b748468a982e770d18b4552a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2810066105484389ab3d11713367a706",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ebbf6b061324a5fa0a0a3a4618c2063"
          }
        },
        "f57ffa8dbb6b42c8a7c1f51084d10c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_413ff0f871204b6a859abdf3b5ca6584",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00, 43.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df13e7d330534fb49daca1937ac37bc1"
          }
        },
        "cecb88b7544a425888ac714327e8ea43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dec226a6334c47d2ba948938f9f28381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2810066105484389ab3d11713367a706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ebbf6b061324a5fa0a0a3a4618c2063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "413ff0f871204b6a859abdf3b5ca6584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df13e7d330534fb49daca1937ac37bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HimashiRathnayake/CMCS-Text-Classification/blob/main/XLM-R/Multi_task_learning_XLM_R_ipynb_(Single_Model_Multiple_Prediction_Heads).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://towardsdatascience.com/how-to-create-and-train-a-multi-task-transformer-model-18c54a146240"
      ],
      "metadata": {
        "id": "Wh0UFPxqQOHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Libraries Setup**"
      ],
      "metadata": {
        "id": "RvthvjMHyW9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install datasets\n",
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "srhWyKfmVSRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad52cda-67b8-482a-eab5-3c097a7b4ede"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.17.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.10.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (5.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save datasets as json files**"
      ],
      "metadata": {
        "id": "WBUYZqi4uWpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import torch\n",
        "from dataclasses import dataclass, field\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Optional, List\n",
        "import datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, load_metric\n",
        "import transformers\n",
        "import torch.nn as nn\n",
        "from google.colab import drive\n",
        "from transformers import (\n",
        "    AutoModel,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorWithPadding,\n",
        "    EvalPrediction,\n",
        "    HfArgumentParser,\n",
        "    PretrainedConfig,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    default_data_collator,\n",
        "    set_seed,\n",
        "    DataCollatorForTokenClassification\n",
        ")\n",
        "from transformers.trainer_utils import get_last_checkpoint\n",
        "from transformers.utils import check_min_version\n",
        "from transformers.utils.versions import require_version\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "metadata": {
        "id": "JEBqHHz_VZ70"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QRPzsxjQTXu",
        "outputId": "79880a58-93a6-47ae-d103-d0e7da175610"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def apply_oversampling(x, y):\n",
        "\n",
        "#   (unique, counts) = np.unique(y, axis=0, return_counts=True)\n",
        "#   print(\"Class Distribution Without Oversampling\", counts)\n",
        "\n",
        "#   oversample = RandomOverSampler(sampling_strategy = {\n",
        "#       0:int(counts[0]*1), 1:int(counts[0]*0.25), 2:int(counts[0]*0.25)})\n",
        "  \n",
        "#   # fit and apply the transform\n",
        "#   X_over, y_over = oversample.fit_resample(x, y)\n",
        "\n",
        "#   (unique, counts) = np.unique(y_over, axis=0, return_counts=True)\n",
        "#   print(\"Class Distribution After Oversampling\", counts)\n",
        "\n",
        "#   return X_over, y_over"
      ],
      "metadata": {
        "id": "62XjL9yXIgqp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sent_dataset_path = \"/content/drive/Shareddrives/FYP/corpus/çompleted_draft.csv\"\n",
        "# task_name = \"Hate_speech\"\n",
        "# df = pd.read_csv(sent_dataset_path)\n",
        "# df = df[['Sentence', task_name]]\n",
        "# df.columns = ['sentence', 'label']\n",
        "# df['label'], uniq = pd.factorize(df['label'])\n",
        "# trainData, testData = train_test_split(df, test_size=0.10, random_state=42)\n",
        "# rosTrainData = pd.DataFrame()\n",
        "\n",
        "# #apply oversampling\n",
        "# X = trainData['sentence'].values.tolist()\n",
        "# y = trainData['label'].values.tolist()\n",
        "# X = np.array(X).reshape(-1, 1)\n",
        "# X, y = apply_oversampling(X, y)\n",
        "# X = [x[0] for x in X.tolist()]\n",
        "# rosTrainData['sentence'] = X\n",
        "# rosTrainData['label'] = y\n",
        "\n",
        "# #save the data\n",
        "# rosTrainData.to_json('/content/drive/Shareddrives/FYP/corpus/hate_ros_train.json', orient='records', lines=True,  force_ascii=False)\n",
        "# testData.to_json('/content/drive/Shareddrives/FYP/corpus/hate_ros_test.json', orient='records', lines=True,  force_ascii=False)\n",
        "\n",
        "# tags_ind = ['Sinhala', 'English', 'Sin-Eng', 'Eng-Sin', 'Mixed', 'NameEntity', 'Symbol']\n",
        "# df = pd.read_json(token_dataset_path, lines=True)\n",
        "# count = 0\n",
        "# for labels in df['tags']:\n",
        "#   temp =[]\n",
        "#   for label in labels:\n",
        "#     temp.append(tags_ind.index(label))\n",
        "#   df['tags'][count] = temp\n",
        "#   count +=1\n",
        "# #split the data into train and test set\n",
        "# trainData,testData = train_test_split(df, test_size=0.10, random_state=42)\n",
        "# #save the data\n",
        "# trainData.to_json('/content/drive/Shareddrives/FYP/corpus/lang_id_train.json', orient='records', lines=True,  force_ascii=False)\n",
        "# testData.to_json('/content/drive/Shareddrives/FYP/corpus/lang_id_test.json', orient='records', lines=True,  force_ascii=False)"
      ],
      "metadata": {
        "id": "92x3-5-BuCnz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 128"
      ],
      "metadata": {
        "id": "7Zvk3JVVSf_f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "53lzyhEeLQBL"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Task:\n",
        "    id: int\n",
        "    name: str\n",
        "    type: str\n",
        "    num_labels: int"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_token_classification_dataset(raw_datasets, tokenizer, task_id, data_args, training_args):\n",
        "\n",
        "    def tokenize_and_align_labels(examples):\n",
        "        tokenized_inputs = tokenizer(\n",
        "            examples[\"tokens\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=data_args.max_seq_length,\n",
        "            # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
        "            is_split_into_words=True,\n",
        "        )\n",
        "        labels = []\n",
        "        for i, label in enumerate(examples[\"tags\"]):\n",
        "            word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "            previous_word_idx = None\n",
        "            label_ids = []\n",
        "            for word_idx in word_ids:\n",
        "                # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "                # ignored in the loss function.\n",
        "                if word_idx is None:\n",
        "                    label_ids.append(-100)\n",
        "                # We set the label for the first token of each word.\n",
        "                elif word_idx != previous_word_idx:\n",
        "                    label_ids.append(label[word_idx])\n",
        "                # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "                # the label_all_tokens flag.\n",
        "                else:\n",
        "                    label_ids.append(label[word_idx] if data_args.label_all_tokens else -100)\n",
        "                previous_word_idx = word_idx\n",
        "            \n",
        "            labels.append(label_ids)\n",
        "\n",
        "        tokenized_inputs[\"labels\"] = labels\n",
        "        tokenized_inputs[\"task_ids\"] = [task_id] * len(tokenized_inputs[\"labels\"])\n",
        "        return tokenized_inputs\n",
        "\n",
        "    with training_args.main_process_first(desc=\"dataset map pre-processing\"):\n",
        "        tokenized_datasets = raw_datasets.map(\n",
        "            tokenize_and_align_labels,\n",
        "            batched=True,\n",
        "            num_proc=1,\n",
        "            load_from_cache_file=not data_args.overwrite_cache,\n",
        "            remove_columns=[\"tokens\"],\n",
        "        )\n",
        "\n",
        "    return tokenized_datasets"
      ],
      "metadata": {
        "id": "CRqsn2Ex2Ujy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_seq_classification_dataset(\n",
        "    tokenizer, raw_datasets, task_id, data_args, training_args\n",
        "):\n",
        "\n",
        "    def tokenize_text(examples):\n",
        "        result = tokenizer(examples[\"sentence\"], padding=\"max_length\", max_length=data_args.max_seq_length, truncation=True)\n",
        "        examples[\"labels\"] = examples.pop(\"label\")\n",
        "        result[\"task_ids\"] = [task_id] * len(examples[\"labels\"])\n",
        "        return result\n",
        "\n",
        "    def tokenize_and_pad_text(examples):\n",
        "        result = tokenizer(examples[\"sentence\"], padding=\"max_length\", max_length=data_args.max_seq_length, truncation=True)\n",
        "        examples[\"labels\"] = examples.pop(\"label\")\n",
        "        result[\"task_ids\"] = [task_id] * len(examples[\"labels\"])\n",
        "        result[\"labels\"] = [\n",
        "            [l] + [-100] * (data_args.max_seq_length - 1) for l in examples[\"labels\"]\n",
        "        ]\n",
        "        return result\n",
        "\n",
        "    with training_args.main_process_first(desc=\"dataset map pre-processing\"):\n",
        "        col_to_remove = [\"sentence\"]\n",
        "        train_dataset = raw_datasets[\"train\"].map(\n",
        "            tokenize_and_pad_text,\n",
        "            batched=True,\n",
        "            load_from_cache_file=not data_args.overwrite_cache,\n",
        "            remove_columns=col_to_remove,\n",
        "            desc=\"Running tokenizer on dataset\",\n",
        "        )\n",
        "        validation_dataset = raw_datasets[\"test\"].map(\n",
        "            tokenize_text,\n",
        "            batched=True,\n",
        "            load_from_cache_file=not data_args.overwrite_cache,\n",
        "            remove_columns=col_to_remove,\n",
        "            desc=\"Running tokenizer on dataset\",\n",
        "        )\n",
        "\n",
        "    return train_dataset, validation_dataset"
      ],
      "metadata": {
        "id": "rnbrO5tf00ce"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_classification_dataset(task_id, task_name, tokenizer, data_args, training_args):\n",
        "\n",
        "    raw_datasets = load_dataset('json', data_files={'train': f'/content/drive/Shareddrives/FYP/corpus/{task_name}_train.json',\n",
        "                                           'test': f'/content/drive/Shareddrives/FYP/corpus/{task_name}_test.json'})\n",
        "\n",
        "    num_labels = 7 if task_name == \"lang_id\" else len(set(raw_datasets[\"train\"][\"label\"]))\n",
        "    task_info = Task(\n",
        "        id=task_id, name=task_name, num_labels=num_labels, type=\"token_classification\" if task_name==\"lang_id\" else \"seq_classification\" \n",
        "    )\n",
        "\n",
        "    if (task_name == \"lang_id\"):\n",
        "        tokenized_datasets = tokenize_token_classification_dataset(\n",
        "            raw_datasets,\n",
        "            tokenizer,\n",
        "            task_id,\n",
        "            data_args,\n",
        "            training_args,\n",
        "        )\n",
        "        return tokenized_datasets[\"train\"], tokenized_datasets[\"test\"], task_info\n",
        "    else:\n",
        "        train_dataset, validation_dataset = tokenize_seq_classification_dataset(\n",
        "            tokenizer,\n",
        "            raw_datasets,\n",
        "            task_id,\n",
        "            data_args,\n",
        "            training_args,\n",
        "        )\n",
        "        return train_dataset, validation_dataset, task_info"
      ],
      "metadata": {
        "id": "B_BvlkkDVOQU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_datasets(tokenizer, data_args, training_args):\n",
        "    (train_data_1, test_data_1, task_1) = load_classification_dataset(0, \"sentiment\", tokenizer, data_args, training_args)\n",
        "    (train_data_2, test_data_2, task_2) = load_classification_dataset(1, \"humor\", tokenizer, data_args, training_args)\n",
        "    (train_data_3, test_data_3, task_3) = load_classification_dataset(2, \"hate_ros\", tokenizer, data_args, training_args)\n",
        "    (train_data_4, test_data_4, task_4) = load_classification_dataset(3, \"lang_id\", tokenizer, data_args, training_args)\n",
        "    \n",
        "    # Merge train datasets\n",
        "    train_dataset_df = train_data_1.to_pandas().append(train_data_2.to_pandas()).append(train_data_3.to_pandas()).append(train_data_4.to_pandas())\n",
        "\n",
        "    train_dataset = datasets.Dataset.from_pandas(train_dataset_df)\n",
        "    train_dataset.shuffle(seed=123)\n",
        "\n",
        "    # Append validation datasets\n",
        "    validation_dataset = [\n",
        "        test_data_1, test_data_2, test_data_3, test_data_4\n",
        "    ]\n",
        "\n",
        "    dataset = datasets.DatasetDict(\n",
        "        {\"train\": train_dataset, \"validation\": validation_dataset}\n",
        "    )\n",
        "    tasks = [task_1, task_2, task_3, task_4]\n",
        "    return tasks, dataset"
      ],
      "metadata": {
        "id": "fkhVBNi6VDtN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, encoder_name_or_path, tasks: List):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = AutoModel.from_pretrained(encoder_name_or_path)\n",
        "\n",
        "        self.output_heads = nn.ModuleDict()\n",
        "        \n",
        "        for task in tasks:\n",
        "            decoder = self._create_output_head(self.encoder.config.hidden_size, task)\n",
        "            # ModuleDict requires keys to be strings\n",
        "            self.output_heads[str(task.id)] = decoder\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_output_head(encoder_hidden_size: int, task):\n",
        "        if task.type == \"seq_classification\":\n",
        "            return SequenceClassificationHead(encoder_hidden_size, task.num_labels)\n",
        "        elif task.type == \"token_classification\":\n",
        "            return TokenClassificationHead(encoder_hidden_size, task.num_labels)\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        task_ids=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "        outputs = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        sequence_output, pooled_output = outputs[:2]\n",
        "\n",
        "        unique_task_ids_list = torch.unique(task_ids).tolist()\n",
        "\n",
        "        loss_list = []\n",
        "        logits = None\n",
        "        for unique_task_id in unique_task_ids_list:\n",
        "\n",
        "            task_id_filter = task_ids == unique_task_id\n",
        "            logits, task_loss = self.output_heads[str(unique_task_id)].forward(\n",
        "                sequence_output[task_id_filter],\n",
        "                pooled_output[task_id_filter],\n",
        "                labels=None if labels is None else labels[task_id_filter],\n",
        "                attention_mask=attention_mask[task_id_filter],\n",
        "            )\n",
        "\n",
        "            if labels is not None:\n",
        "                loss_list.append(task_loss)\n",
        "\n",
        "        # logits are only used for eval. and in case of eval the batch is not multi task\n",
        "        # For training only the loss is used\n",
        "        outputs = (logits, outputs[2:])\n",
        "\n",
        "        if loss_list:\n",
        "            loss = torch.stack(loss_list)\n",
        "            outputs = (loss.mean(),) + outputs\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "xFRgBWHTUrYF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenClassificationHead(nn.Module):\n",
        "    def __init__(self, hidden_size, num_labels, dropout_p=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        self.classifier.weight.data.normal_(mean=0.0, std=0.02)\n",
        "        if self.classifier.bias is not None:\n",
        "            self.classifier.bias.data.zero_()\n",
        "\n",
        "    def forward(\n",
        "        self, sequence_output, pooled_output, labels=None, attention_mask=None, **kwargs\n",
        "    ):\n",
        "        sequence_output_dropout = self.dropout(sequence_output)\n",
        "        logits = self.classifier(sequence_output_dropout)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "            labels = labels.long()\n",
        "\n",
        "            # Only keep active parts of the loss\n",
        "            if attention_mask is not None:\n",
        "                active_loss = attention_mask.view(-1) == 1\n",
        "                active_logits = logits.view(-1, self.num_labels)\n",
        "                active_labels = torch.where(\n",
        "                    active_loss,\n",
        "                    labels.view(-1),\n",
        "                    torch.tensor(loss_fct.ignore_index).type_as(labels),\n",
        "                )\n",
        "                loss = loss_fct(active_logits, active_labels)\n",
        "            else:\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        return logits, loss"
      ],
      "metadata": {
        "id": "Q2Y5Rvu8EpTb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceClassificationHead(nn.Module):\n",
        "    def __init__(self, hidden_size, num_labels, dropout_p=0.1):\n",
        "        super().__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def forward(self, sequence_output, pooled_output, labels=None, **kwargs):\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if labels.dim() != 1:\n",
        "                # Remove padding\n",
        "                labels = labels[:, 0]\n",
        "\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(\n",
        "                logits.view(-1, self.num_labels), labels.long().view(-1)\n",
        "            )\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def _init_weights(self):\n",
        "        self.classifier.weight.data.normal_(mean=0.0, std=0.02)\n",
        "        if self.classifier.bias is not None:\n",
        "            self.classifier.bias.data.zero_()"
      ],
      "metadata": {
        "id": "diioG2QuEzXh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "    \n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "\n",
        "    if preds.ndim == 2:\n",
        "        # Sequence classification\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "        labels = p.label_ids\n",
        "        # print(preds, labels)\n",
        "        # return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}\n",
        "\n",
        "        metric1 = load_metric(\"precision\")\n",
        "        metric2 = load_metric(\"recall\")\n",
        "        metric3 = load_metric(\"f1\")\n",
        "        metric4 = load_metric(\"accuracy\")\n",
        "        \n",
        "        precision = metric1.compute(predictions=preds, references=labels, average=\"weighted\")[\"precision\"]\n",
        "        recall = metric2.compute(predictions=preds, references=labels, average=\"weighted\")[\"recall\"]\n",
        "        f1 = metric3.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"]\n",
        "        accuracy = metric4.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
        "        macro_precision = metric1.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"]\n",
        "        macro_recall = metric2.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"]\n",
        "        macro_f1 = metric3.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
        "        return {\"accuracy\":accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"macro_precision\": macro_precision, \"macro_recall\": macro_recall, \"macro_f1\": macro_f1}\n",
        "    \n",
        "    elif preds.ndim == 3:\n",
        "        # Token classification\n",
        "        metric = load_metric(\"seqeval\")\n",
        "\n",
        "        predictions = np.argmax(preds, axis=2)\n",
        "\n",
        "        true_predictions = [\n",
        "            [f\"tag-idx-{p}\" for (p, l) in zip(prediction, label) if l != -100]\n",
        "            for prediction, label in zip(predictions, p.label_ids)\n",
        "        ]\n",
        "        true_labels = [\n",
        "            [f\"tag-idx-{l}\" for (p, l) in zip(prediction, label) if l != -100]\n",
        "            for prediction, label in zip(predictions, p.label_ids)\n",
        "        ]\n",
        "\n",
        "        # Remove ignored index (special tokens)\n",
        "        results = metric.compute(\n",
        "            predictions=true_predictions, references=true_labels\n",
        "        )\n",
        "        return {\n",
        "            \"precision\": results[\"overall_precision\"],\n",
        "            \"recall\": results[\"overall_recall\"],\n",
        "            \"f1\": results[\"overall_f1\"],\n",
        "            \"accuracy\": results[\"overall_accuracy\"],\n",
        "        }\n",
        "    else:\n",
        "        raise NotImplementedError()"
      ],
      "metadata": {
        "id": "TmVdEZkdE0Q9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ModelArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
        "    \"\"\"\n",
        "\n",
        "    encoder_name_or_path: str = field(\n",
        "        default=\"xlm-roberta-base\",\n",
        "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
        "    )\n",
        "    config_name: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
        "    )\n",
        "    tokenizer_name: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
        "    )\n",
        "    cache_dir: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
        "    )\n",
        "    use_fast_tokenizer: bool = field(\n",
        "        default=False,\n",
        "        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},\n",
        "    )\n",
        "    model_revision: str = field(\n",
        "        default=\"main\",\n",
        "        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n",
        "    )\n",
        "    use_auth_token: bool = field(\n",
        "        default=False,\n",
        "        metadata={\n",
        "            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n",
        "            \"with private models).\"\n",
        "        },\n",
        "    )"
      ],
      "metadata": {
        "id": "M9hz6PKUem2K"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_to_keys = {\n",
        "        \"cola\": (\"sentence\", None),\n",
        "        \"mnli\": (\"premise\", \"hypothesis\"),\n",
        "        \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
        "        \"qnli\": (\"question\", \"sentence\"),\n",
        "        \"qqp\": (\"question1\", \"question2\"),\n",
        "        \"rte\": (\"sentence1\", \"sentence2\"),\n",
        "        \"sst2\": (\"sentence\", None),\n",
        "        \"stsb\": (\"sentence1\", \"sentence2\"),\n",
        "        \"wnli\": (\"sentence1\", \"sentence2\"),\n",
        "    }\n",
        "\n",
        "@dataclass\n",
        "class DataTrainingArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
        "    Using `HfArgumentParser` we can turn this class\n",
        "    into argparse arguments to be able to specify them on\n",
        "    the command line.\n",
        "    \"\"\"\n",
        "\n",
        "    task_name: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"The name of the task to train on: \" + \", \".join(task_to_keys.keys())},\n",
        "    )\n",
        "    dataset_name: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
        "    )\n",
        "    dataset_config_name: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
        "    )\n",
        "    max_seq_length: int = field(\n",
        "        default=128,\n",
        "        metadata={\n",
        "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "            \"than this will be truncated, sequences shorter will be padded.\"\n",
        "        },\n",
        "    )\n",
        "    overwrite_cache: bool = field(\n",
        "        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n",
        "    )\n",
        "    pad_to_max_length: bool = field(\n",
        "        default=True,\n",
        "        metadata={\n",
        "            \"help\": \"Whether to pad all samples to `max_seq_length`. \"\n",
        "            \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n",
        "        },\n",
        "    )\n",
        "    max_train_samples: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
        "            \"value if set.\"\n",
        "        },\n",
        "    )\n",
        "    max_eval_samples: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
        "            \"value if set.\"\n",
        "        },\n",
        "    )\n",
        "    max_predict_samples: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n",
        "            \"value if set.\"\n",
        "        },\n",
        "    )\n",
        "    train_file: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"A csv or a json file containing the training data.\"}\n",
        "    )\n",
        "    validation_file: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"A csv or a json file containing the validation data.\"}\n",
        "    )\n",
        "    label_all_tokens: Optional[bool] = field(\n",
        "        default=True, metadata={\"help\": \"A csv or a json file containing the validation data.\"}\n",
        "    )\n",
        "    test_file: Optional[str] = field(default=None, metadata={\"help\": \"A csv or a json file containing the test data.\"})"
      ],
      "metadata": {
        "id": "1pJauugCe1Ji"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_args = ModelArguments(encoder_name_or_path=\"xlm-roberta-base\")\n",
        "data_args = DataTrainingArguments(max_seq_length=128)\n",
        "training_args = TrainingArguments(\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    output_dir=\"/tmp/test\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_train_batch_size=32,  \n",
        "    per_device_eval_batch_size=32,\n",
        "    save_steps=10000,\n",
        ")"
      ],
      "metadata": {
        "id": "gjmn1EEtNdVW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_args.encoder_name_or_path,\n",
        "    # cache_dir=model_args.cache_dir,\n",
        "    # use_fast=model_args.use_fast_tokenizer,\n",
        "    # revision=model_args.model_revision,\n",
        "    # use_auth_token=True if model_args.use_auth_token else None,\n",
        "    do_lower_case=True\n",
        ")"
      ],
      "metadata": {
        "id": "EAjyvCwcNyYa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(training_args.seed)\n",
        "tasks, raw_datasets = load_datasets(tokenizer, data_args, training_args)\n",
        "model = MultiTaskModel(model_args.encoder_name_or_path, tasks)\n",
        "train_dataset = raw_datasets[\"train\"]\n",
        "eval_datasets = raw_datasets[\"validation\"]\n",
        "data_collator = DataCollatorForTokenClassification(\n",
        "    tokenizer, pad_to_multiple_of=8 if training_args.fp16 else None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525,
          "referenced_widgets": [
            "cdb2d0f45f874b8bb5119801a7ce5399",
            "9bb37b484c8c4f3b8971890d157fd11f",
            "bbcad7709f824a4896202106ba1a72ee",
            "ddabccdbd498420891d0daf5d4927324",
            "aa732a5a3d634e04a285890bbe07b79e",
            "97ca980f5246466a8c728b134316cdaa",
            "4b00b04fc068493a99a8d82ef34ee5e1",
            "df592d5b2e454e9289db7ba65688afae",
            "93a1f187552a46d1ad151f0b901a5669",
            "3763b6daef2248dea55cef92d1f28a49",
            "1732ca7b88134f34b2390c661c0af0d9",
            "f6914c03d01d49a8a5f96abf357251ef",
            "fb702ae270e64c6cb27b2013b9444fcb",
            "c4a99603814547d88cbb6bc7373f78d7",
            "b631233f0af947d093075645b7fd1549",
            "7f86d36d71ac4a679ce387418c5bc359",
            "8a2e1fa9222f4e0ca90a394d1ebe8f62",
            "a133950e2f574b7ea342afd35269154e",
            "a8de4c137a444b8f960bad048e7bb500",
            "42b4b88bdf4140569509e88ec2efa82a",
            "041c0de5c10e42858fe08fcb7bbce5f6",
            "f75948d7c56243599209379747c932ce",
            "b981258076634e6bb64b27b5c67c5a00",
            "03ce92528ba44d2fa48eb1a655293aaa",
            "4ff38f49f2464b15a6877382dda6f796",
            "fde148cc39e4485bb25bc5d970a06ec4",
            "afbe4437399340918039777567baded5",
            "490f205d353c4a3ab8144c0c54e1dd6c",
            "f2573c5ba5364024b86bd4de48bb796b",
            "c2c79764d13040f08ad7200a86c32ae1",
            "86ff1ca464fa455f9e6b47ac2b080e3c",
            "88c76e4c7d3e404f9ff2ca7c52ac0dbb",
            "8c1bebf7def7474ebd4e9a568b6b8305",
            "5f757735901a4ceba6d6320aaf64c1db",
            "f504de45539f4d7da003ea8e938d1466",
            "db94c0ecb210485e9e80312cf98158d3",
            "d62cd1b38a6c4084aee8427955c70b50",
            "0774ddf6df7b4cec8f4824c8856cc6d0",
            "cbd2555633574c1db3f83eea43b7450d",
            "36f35d95617c45aea109c5df9e8b58cb",
            "79d85333b387418a86fbc32d72c2b5e8",
            "d2d15581ccd54720a3c576122ba76028",
            "25250bff22ef4448a2ad00371d573ff3",
            "52dae32a698542c38568006a38a8057e",
            "c8a07829f8104db2bc91ae5759005e3f",
            "c0069bf396d44bd9b2c390fb38ae2240",
            "5f13d97a3a144eaa9a54b834954e0028",
            "b0e28d61b748468a982e770d18b4552a",
            "f57ffa8dbb6b42c8a7c1f51084d10c29",
            "cecb88b7544a425888ac714327e8ea43",
            "dec226a6334c47d2ba948938f9f28381",
            "2810066105484389ab3d11713367a706",
            "6ebbf6b061324a5fa0a0a3a4618c2063",
            "413ff0f871204b6a859abdf3b5ca6584",
            "df13e7d330534fb49daca1937ac37bc1"
          ]
        },
        "id": "QxOL8cFEN7iY",
        "outputId": "86e05329-715b-4aa3-d0fa-28a314a1db22"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-3f0a22b1e59e6040\n",
            "Reusing dataset json (/root/.cache/huggingface/datasets/json/default-3f0a22b1e59e6040/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdb2d0f45f874b8bb5119801a7ce5399",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-3f0a22b1e59e6040/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde/cache-7dfd6b0ce1a19d03.arrow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6914c03d01d49a8a5f96abf357251ef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/2 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-4605e1ab69a23fa1\n",
            "Reusing dataset json (/root/.cache/huggingface/datasets/json/default-4605e1ab69a23fa1/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b981258076634e6bb64b27b5c67c5a00",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-4605e1ab69a23fa1/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde/cache-903e21f8f2a0b5e9.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-4605e1ab69a23fa1/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde/cache-1445f873ec45dd05.arrow\n",
            "Using custom data configuration default-71140e368f460cc9\n",
            "Reusing dataset json (/root/.cache/huggingface/datasets/json/default-71140e368f460cc9/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f757735901a4ceba6d6320aaf64c1db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-71140e368f460cc9/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde/cache-c15ad63629bddcbd.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-71140e368f460cc9/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde/cache-0e204d97785a2bdb.arrow\n",
            "Using custom data configuration default-0b5eb83830de93b0\n",
            "Reusing dataset json (/root/.cache/huggingface/datasets/json/default-0b5eb83830de93b0/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8a07829f8104db2bc91ae5759005e3f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-0b5eb83830de93b0/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde/cache-d3f7af633edc7f63.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-0b5eb83830de93b0/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde/cache-4a0a84ea02ea6454.arrow\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize our Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "Kf0zjNx3N-6_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "if training_args.do_train:\n",
        "    train_result = trainer.train()\n",
        "    metrics = train_result.metrics\n",
        "    max_train_samples = (\n",
        "        data_args.max_train_samples\n",
        "        if data_args.max_train_samples is not None\n",
        "        else len(train_dataset)\n",
        "    )\n",
        "    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
        "\n",
        "    trainer.save_model()  # Saves the tokenizer too for easy upload\n",
        "\n",
        "    trainer.log_metrics(\"train\", metrics)\n",
        "    trainer.save_metrics(\"train\", metrics)\n",
        "    trainer.save_state()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uYb76Nh6OJ54",
        "outputId": "0c7f674e-cafe-4b00-857d-36622bbdef2b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: __index_level_0__, tags.\n",
            "***** Running training *****\n",
            "  Num examples = 52964\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4968\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3774' max='4968' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3774/4968 45:43 < 14:28, 1.37 it/s, Epoch 2.28/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.657900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.565400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.528300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.490500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.471600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.448700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.430600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4968' max='4968' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4968/4968 1:00:16, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.657900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.565400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.528300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.490500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.471600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.448700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.430600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.420100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.406400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to /tmp/test\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in /tmp/test/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/test/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  total_flos               =        0GF\n",
            "  train_loss               =     0.4812\n",
            "  train_runtime            = 1:00:17.05\n",
            "  train_samples            =      52964\n",
            "  train_samples_per_second =     43.929\n",
            "  train_steps_per_second   =      1.373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "if training_args.do_eval:\n",
        "\n",
        "    for eval_dataset, task in zip(eval_datasets, tasks):\n",
        "        print(task)\n",
        "        data_collator = None\n",
        "        if task.type == \"token_classification\":\n",
        "            data_collator = DataCollatorForTokenClassification(\n",
        "                tokenizer, pad_to_multiple_of=8 if training_args.fp16 else None\n",
        "            )\n",
        "        else:\n",
        "            if data_args.pad_to_max_length:\n",
        "                data_collator = default_data_collator\n",
        "            elif training_args.fp16:\n",
        "                data_collator = DataCollatorWithPadding(\n",
        "                    tokenizer, pad_to_multiple_of=8\n",
        "                )\n",
        "            else:\n",
        "                data_collator = None\n",
        "\n",
        "        trainer.data_collator = data_collator\n",
        "        metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
        "\n",
        "        max_eval_samples = (\n",
        "            data_args.max_eval_samples\n",
        "            if data_args.max_eval_samples is not None\n",
        "            else len(eval_datasets)\n",
        "        )\n",
        "        metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_datasets))\n",
        "\n",
        "        trainer.log_metrics(\"eval\", metrics)\n",
        "        trainer.save_metrics(\"eval\", metrics)"
      ],
      "metadata": {
        "id": "4_KQCAZSKRGO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3143ba86-1311-492d-b68e-e3fbff42c91e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task(id=0, name='sentiment', type='seq_classification', num_labels=4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='171' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [43/43 00:38]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_accuracy           =     0.7685\n",
            "  eval_f1                 =     0.7625\n",
            "  eval_loss               =     0.6233\n",
            "  eval_macro_f1           =     0.5044\n",
            "  eval_macro_precision    =     0.5277\n",
            "  eval_macro_recall       =     0.4897\n",
            "  eval_precision          =     0.7596\n",
            "  eval_recall             =     0.7685\n",
            "  eval_runtime            = 0:00:10.13\n",
            "  eval_samples            =          4\n",
            "  eval_samples_per_second =    133.397\n",
            "  eval_steps_per_second   =      4.243\n",
            "Task(id=1, name='humor', type='seq_classification', num_labels=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1352\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_accuracy           =     0.9253\n",
            "  eval_f1                 =     0.9045\n",
            "  eval_loss               =     0.2276\n",
            "  eval_macro_f1           =     0.6221\n",
            "  eval_macro_precision    =     0.8101\n",
            "  eval_macro_recall       =     0.5857\n",
            "  eval_precision          =     0.9105\n",
            "  eval_recall             =     0.9253\n",
            "  eval_runtime            = 0:00:09.69\n",
            "  eval_samples            =          4\n",
            "  eval_samples_per_second =    139.413\n",
            "  eval_steps_per_second   =      4.434\n",
            "Task(id=2, name='hate_ros', type='seq_classification', num_labels=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: tags.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1343\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_accuracy           =     0.8469\n",
            "  eval_f1                 =     0.8681\n",
            "  eval_loss               =     0.3949\n",
            "  eval_macro_f1           =     0.5385\n",
            "  eval_macro_precision    =     0.5054\n",
            "  eval_macro_recall       =     0.6826\n",
            "  eval_precision          =     0.9006\n",
            "  eval_recall             =     0.8469\n",
            "  eval_runtime            = 0:00:09.68\n",
            "  eval_samples            =          4\n",
            "  eval_samples_per_second =    139.532\n",
            "  eval_steps_per_second   =      4.438\n",
            "Task(id=3, name='lang_id', type='token_classification', num_labels=7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: tag-idx-0 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: tag-idx-5 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: tag-idx-3 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: tag-idx-1 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: tag-idx-6 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: tag-idx-2 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: tag-idx-4 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_accuracy           =      0.966\n",
            "  eval_f1                 =     0.9088\n",
            "  eval_loss               =     0.1204\n",
            "  eval_precision          =     0.9119\n",
            "  eval_recall             =     0.9057\n",
            "  eval_runtime            = 0:00:10.39\n",
            "  eval_samples            =          4\n",
            "  eval_samples_per_second =    129.254\n",
            "  eval_steps_per_second   =      4.042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YTCrIRnhQtvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Orh9YE0Wj_r8"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}
